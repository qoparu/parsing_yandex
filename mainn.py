import os
import re
import csv
import time
import cv2
import pickle
import argparse
from streetlevel import yandex
from datetime import datetime
from typing import Optional, List
from PIL import Image
import imagehash
import numpy as np
from py360convert import e2p

# ==============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==============================================================================
INPUT_CSV = "almaty_roads.csv"
OUTPUT_DIR_BASE = "output"
TEMP_DIR = "temp_panoramas"
TIME_DELAY = 1.0

# ==============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================================================================
def transliterate(string: str) -> str:
    cyrillic_to_latin = {
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'E', '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I',
        '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M', '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T',
        '–£': 'U', '–§': 'F', '–•': 'Kh', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Shch', '–™': '', '–´': 'Y',
        '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya', '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd',
        '–µ': 'e', '—ë': 'e', '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u', '—Ñ': 'f', '—Ö': 'kh',
        '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch', '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu',
        '—è': 'ya', '”ò': 'A', '”ô': 'a', '“í': 'G', '“ì': 'g', '“ö': 'Q', '“õ': 'q', '“¢': 'N', '“£': 'n',
        '”®': 'O', '”©': 'o', '“∞': 'U', '“±': 'u', '“Æ': 'U', '“Ø': 'u', '“∫': 'H', '“ª': 'h', '–Ü': 'I', '—ñ': 'i'
    }
    return ''.join(cyrillic_to_latin.get(char, char) for char in string)
def fix_encoding(s: str) -> str:
    if not isinstance(s, str) or not s: return s
    try: return s.encode("cp1251").decode("utf-8")
    except Exception: return s
def get_date_from_pano_id(pano_id: str) -> Optional[datetime]:
    parts = pano_id.split("_");
    if not parts: return None
    try:
        return datetime.utcfromtimestamp(int(parts[-1]))
    except (ValueError, IndexError, TypeError):
        return None
def autocrop_image(img: np.ndarray) -> np.ndarray:
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mask = cv2.inRange(gray, 10, 245)
    coords = cv2.findNonZero(mask)
    if coords is None:
        return img
    x, y, w, h = cv2.boundingRect(coords)
    if w == 0 or h == 0:
        print("   -> –ê–≤—Ç–æ–æ–±—Ä–µ–∑–∫–∞ –¥–∞–ª–∞ –Ω—É–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
        return img
    return img[y:y+h, x:x+w]
    
#–§—É–Ω–∫—Ü–∏—è –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏ –ø–∞–Ω–æ—Ä–∞–º—ã –Ω–∞ –≤–∏–¥—ã "–≤–ø–µ—Ä–µ–¥" –∏ "–Ω–∞–∑–∞–¥"
def crop_panorama_to_roi(img: np.ndarray, year: str) -> List[dict]:
    """
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–∞–Ω–æ—Ä–∞–º—É, –Ω–∞—Ä–µ–∑–∞–µ—Ç –µ–µ –Ω–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –≤–∏–¥—ã (–≤–ø–µ—Ä–µ–¥/–Ω–∞–∑–∞–¥)
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∏–¥ –∏ –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏–µ.
    """
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏ –æ–±—Ä–µ–∑–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ª–µ—Ç, –∫–∞–∫ –º—ã –¥–µ–ª–∞–ª–∏ —Ä–∞–Ω—å—à–µ
    profiles = {
        "default": {"v_deg": -20, "top_frac": 0.5, "end_frac": 1.0, "sub_crop": 0.3},
        "2017": {"v_deg": -7, "top_frac": 0.4, "end_frac": 0.9, "sub_crop": 0.1}
    }
    profile = profiles.get(year, profiles["default"])
    
    output_views = []
    
    for yaw, view_label in [(180, "front"), (0, "back")]:
        view = e2p(img, fov_deg=70, u_deg=yaw, v_deg=profile["v_deg"], out_hw=(1536, 1536))
        h, _, _ = view.shape
        
        top_px = int(h * profile["top_frac"])
        end_px = int(h * profile["end_frac"])
        primary_crop = view[top_px:end_px, :, :]
        
        h_sub, _, _ = primary_crop.shape
        sub_crop_px = int(h_sub * profile["sub_crop"])
        final_crop = primary_crop[sub_crop_px:, :, :]
        
        output_views.append({"label": view_label, "image": final_crop})
        
    return output_views

# ==============================================================================
# –ì–õ–ê–í–ù–´–ô –°–ö–†–ò–ü–¢
# ==============================================================================
def main():
    parser = argparse.ArgumentParser(description="–°–±–æ—Ä—â–∏–∫ –ø–∞–Ω–æ—Ä–∞–º –Ø–Ω–¥–µ–∫—Å –ø–æ –≥–æ–¥–∞–º.")
    parser.add_argument("year", type=int, nargs='?', default=None, help="–ì–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2023). –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –±—É–¥–µ—Ç –∑–∞–ø—Ä–æ—à–µ–Ω.")
    args = parser.parse_args()
    if args.year:
        YEAR = str(args.year)
    else:
        YEAR = input("‚û°Ô∏è –í–≤–µ–¥–∏—Ç–µ –≥–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2023): ")
    if not YEAR.isdigit() or not (2010 < int(YEAR) < 2030):
        print(f"‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≥–æ–¥: {YEAR}. –í—ã—Ö–æ–¥."); exit()
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è {YEAR} –≥–æ–¥–∞.")
    output_dir = os.path.join(OUTPUT_DIR_BASE, YEAR)
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(TEMP_DIR, exist_ok=True)
    log_file = os.path.join(output_dir, f"metadata_{YEAR}.csv")
    bad_addresses_file = os.path.join(output_dir, f"no_panorama_addresses_{YEAR}.csv")
    state_path = os.path.join(output_dir, "state.pkl")
    cache_path = os.path.join(TEMP_DIR, "panorama_cache.pkl")
    if not os.path.exists(log_file):
        with open(log_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            # NEW ROI: –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–æ–Ω–∫—É View –≤ –ª–æ–≥
            writer.writerow(["ID", "ObjectID", "PanoID", "RoadName", "Latitude", "Longitude", "YearFound", "View", "FilePath", "PanoramaDate"])
    try:
        with open(cache_path, "rb") as f: panorama_cache = pickle.load(f)
    except (FileNotFoundError, EOFError): panorama_cache = {}
    try:
        with open(state_path, "rb") as f: state = pickle.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è {YEAR} –≥–æ–¥–∞.")
    except (FileNotFoundError, EOFError):
        state = { 'processed_coords': set(), 'image_hashes': set(), 'stats': {'total_duration_seconds': 0.0} }
        print(f"‚ÑπÔ∏è –§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è {YEAR} –≥–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π.")
    processed_coords = state['processed_coords']
    image_hashes = state['image_hashes']
    stats = state['stats']
    print(f"-> –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {len(processed_coords)}")
    print(f"-> –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_hashes)}")
    logged_pano_ids = set()
    global_id = 0
    try:
        with open(log_file, 'r', newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('PanoID'): logged_pano_ids.add(row['PanoID'])
                if row.get('ID') and row['ID'].isdigit():
                    current_id = int(row['ID'])
                    if current_id > global_id: global_id = current_id
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(logged_pano_ids)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∞–Ω–æ—Ä–∞–º –≤ –ª–æ–≥–µ. –ù–∞—á–∞–ª—å–Ω—ã–π ID: {global_id}")
    except FileNotFoundError:
        print("‚ÑπÔ∏è –õ–æ–≥-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è.")
    all_roads_data = []
    with open(INPUT_CSV, mode="r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_name, object_id = (row.get("name") or row.get("name_ru") or "").strip(), row.get("objectid")
            if not raw_name or not object_id: continue
            road_name, geom = fix_encoding(raw_name), (row.get("geometry_wkt") or "").strip()
            coords_pairs = re.findall(r"([-\d\.]+)\s+([-\d\.]+)", geom)
            if not coords_pairs: continue
            path = [(float(lat), float(lon)) for lon, lat in coords_pairs]
            all_roads_data.append({ "name": road_name, "object_id": object_id, "path": path })
    if not all_roads_data:
        print("‚ö†Ô∏è –ü–æ—Å–ª–µ —á—Ç–µ–Ω–∏—è almaty_roads.csv –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –∞–¥—Ä–µ—Å–∞."); exit(1)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(all_roads_data)} –¥–æ—Ä–æ–∂–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    print(">>> –°–¢–ê–†–¢ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–ª–∏—Ü")
    start_time = time.time()
    streets_processed_this_session, coords_processed_this_session = 0, 0
    total_coords_in_file = sum(len(road['path']) for road in all_roads_data)
    try:
        for road in all_roads_data:
            road_name, object_id, segment_path = road['name'], road['object_id'], road['path']
            print(f"\n=================================================")
            print(f"üõ£Ô∏è  –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç: ¬´{road_name}¬ª (ObjectID: {object_id})")
            
            sanitized_name = transliterate(road_name).replace(" ", "_").replace("/", "-")
            
            for lat, lon in segment_path:
                if (lat, lon) in processed_coords:
                    continue
                coords_processed_this_session += 1
                print(f"\nüìç –¢–æ—á–∫–∞: ({lat:.6f}, {lon:.6f}) [{len(processed_coords)}/{total_coords_in_file}]")
                
                pano_to_process = None
                try:
                    time.sleep(TIME_DELAY)
                    latest_pano = yandex.find_panorama(lat, lon)
                    if not latest_pano: raise StopIteration("–ü–∞–Ω–æ—Ä–∞–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–π —Ç–æ—á–∫–∏.")
                    all_panos_at_location = [latest_pano] + getattr(latest_pano, 'historical', [])
                    
                    found_pano_for_year = None
                    for pano_candidate in all_panos_at_location:
                        pano_date = getattr(pano_candidate, 'date', None) or get_date_from_pano_id(pano_candidate.id)
                        if pano_date and pano_date.year == int(YEAR):
                            if pano_candidate.id in logged_pano_ids:
                                print(f"   ‚ÑπÔ∏è –ù–∞–π–¥–µ–Ω–∞ –ø–∞–Ω–æ—Ä–∞–º–∞ {YEAR} –≥–æ–¥–∞ ({pano_candidate.id}), –Ω–æ –æ–Ω–∞ —É–∂–µ –≤ –ª–æ–≥–µ.")
                            else:
                                print(f"   üéØ –ù–∞–π–¥–µ–Ω–∞ –ø–∞–Ω–æ—Ä–∞–º–∞ –∑–∞ {YEAR} –≥–æ–¥! ID: {pano_candidate.id}")
                                found_pano_for_year = pano_candidate
                            break 
                    
                    if found_pano_for_year:
                        if getattr(found_pano_for_year, 'image_sizes', None) is None:
                            print(f"   -> –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø–∞–Ω–æ—Ä–∞–º—ã...")
                            time.sleep(TIME_DELAY) 
                            pano_to_process = yandex.find_panorama_by_id(found_pano_for_year.id)
                        else:
                            pano_to_process = found_pano_for_year
                    else:
                        print(f"   ‚ÑπÔ∏è –ü–∞–Ω–æ—Ä–∞–º—ã –∑–∞ {YEAR} –≥–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–π —Ç–æ—á–∫–∏.")
                except StopIteration as e: print(f"   {e}")
                except Exception as e:
                    if "Expecting value" in str(e): print(f"   ‚ÑπÔ∏è API –Ø–Ω–¥–µ–∫—Å–∞ –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ—á–∫—É.")
                    else: print(f"   ‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                
                if pano_to_process and pano_to_process.image_sizes:
                    pano = pano_to_process
                    pano_date = getattr(pano, 'date', None) or get_date_from_pano_id(pano.id)
                    raw_path = os.path.join(TEMP_DIR, f"{pano.id}.jpg")
                    if not os.path.exists(raw_path):
                        print(f"   -> –°–∫–∞—á–∏–≤–∞–µ–º –ø–∞–Ω–æ—Ä–∞–º—É {pano.id}...")
                        yandex.download_panorama(pano, raw_path, zoom=0)
                    
                    img = cv2.imread(raw_path)
                    if img is not None:
                        # NEW ROI: –í—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –Ω–∞—Ä–µ–∑–∫–∏
                        views_to_save = crop_panorama_to_roi(img, YEAR)

                        for view_data in views_to_save:
                            view_label = view_data["label"]
                            view_image = view_data["image"]
                            
                            pil_img = Image.fromarray(cv2.cvtColor(view_image, cv2.COLOR_BGR2RGB))
                            h_hash = imagehash.phash(pil_img)

                            if h_hash in image_hashes:
                                print(f"   ‚ÑπÔ∏è –î—É–±–ª–∏–∫–∞—Ç –≤–∏–¥–∞ '{view_label}'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                                continue
                            
                            current_id = global_id + 1
                            filename = f"{YEAR}_{current_id:05d}_{sanitized_name}_{view_label}.jpg"
                            filepath = os.path.join(output_dir, filename)
                            
                            if cv2.imwrite(filepath, view_image):
                                global_id = current_id
                                image_hashes.add(h_hash)
                                logged_pano_ids.add(pano.id) # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π ID, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–∞–Ω–æ—Ä–∞–º—É –∑–∞–Ω–æ–≤–æ
                                with open(log_file, "a", newline="", encoding="utf-8") as f_log:
                                    writer = csv.writer(f_log)
                                    writer.writerow([global_id, object_id, pano.id, road_name, pano.lat, pano.lon, YEAR, view_label, filepath, pano_date.strftime("%Y-%m-%d %H:%M:%S")])
                                print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –≤–∏–¥ '{view_label}': {filepath}")
                    else:
                        print(f"   √ó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞: {raw_path}")
                else:
                    with open(bad_addresses_file, "a", newline="", encoding="utf-8") as f_bad:
                        writer = csv.writer(f_bad); writer.writerow([road_name, lat, lon, object_id])
                
                processed_coords.add((lat, lon))
            
            streets_processed_this_session += 1
            print(f"   ‚úÖ –°–µ–≥–º–µ–Ω—Ç ¬´{road_name}¬ª (ObjectID: {object_id}) –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
    
    except KeyboardInterrupt:
        print("\n\n‚ùóÔ∏è –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
    finally:
        # ... (–±–ª–æ–∫ finally –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        print("\n>>> –ó–ê–í–ï–†–®–ï–ù–ò–ï –†–ê–ë–û–¢–´...")
        session_duration_seconds = time.time() - start_time
        stats['total_duration_seconds'] += session_duration_seconds
        state['processed_coords'] = processed_coords
        state['image_hashes'] = image_hashes
        state['stats'] = stats
        with open(state_path, "wb") as f_state: pickle.dump(state, f_state)
        with open(cache_path, "wb") as f_cache: pickle.dump(panorama_cache, f_cache)
        print("   -> –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        
        m, s = divmod(session_duration_seconds, 60)
        h, m = divmod(m, 60)
        session_duration_formatted = f"{int(h):02d}:{int(m):02d}:{int(s):02d}"
        m_total, s_total = divmod(stats['total_duration_seconds'], 60)
        h_total, m_total = divmod(m_total, 60)
        total_duration_formatted = f"{int(h_total):02d}:{int(m_total):02d}:{int(s_total):02d}"
        print("-" * 50)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"üïí –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—Å–µ—Å—Å–∏—è): {session_duration_formatted}")
        print(f"üïí –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–≤—Å–µ–≥–æ):  {total_duration_formatted}")
        print(f"üõ£Ô∏è  –°–µ–≥–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (—Å–µ—Å—Å–∏—è):  {streets_processed_this_session}")
        print(f"üìç –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç (–≤—Å–µ–≥–æ):         {len(processed_coords)} / {total_coords_in_file}")
        print(f"üñºÔ∏è  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ (–≤—Å–µ–≥–æ):     {global_id}")
        print("-" * 50)
        print(">>> –§–ò–ù–ò–®")


if __name__ == "__main__":
    main()

