import os
import re
import csv
import time
import cv2
import pickle
import argparse
import shutil
from streetlevel import yandex
from datetime import datetime
from typing import Optional, List
from PIL import Image
import imagehash
import numpy as np

# ==============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==============================================================================

# --- –û—Å–Ω–æ–≤–Ω—ã–µ –ø—É—Ç–∏ ---
INPUT_CSV = "almaty_roads.csv"
OUTPUT_DIR_BASE = "output"
TEMP_DIR = "temp_panoramas"

# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ ---
TIME_DELAY = 1.0  #–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ API

# ==============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==============================================================================

def transliterate(string: str) -> str:
    """–¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É —Å –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü—É –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤."""
    # ... (–∫–æ–¥ —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
    cyrillic_to_latin = {
        '–ê': 'A', '–ë': 'B', '–í': 'V', '–ì': 'G', '–î': 'D', '–ï': 'E', '–Å': 'E', '–ñ': 'Zh', '–ó': 'Z', '–ò': 'I',
        '–ô': 'Y', '–ö': 'K', '–õ': 'L', '–ú': 'M', '–ù': 'N', '–û': 'O', '–ü': 'P', '–†': 'R', '–°': 'S', '–¢': 'T',
        '–£': 'U', '–§': 'F', '–•': 'Kh', '–¶': 'Ts', '–ß': 'Ch', '–®': 'Sh', '–©': 'Shch', '–™': '', '–´': 'Y',
        '–¨': '', '–≠': 'E', '–Æ': 'Yu', '–Ø': 'Ya', '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd',
        '–µ': 'e', '—ë': 'e', '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u', '—Ñ': 'f', '—Ö': 'kh',
        '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'shch', '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu',
        '—è': 'ya', '”ò': 'A', '”ô': 'a', '“í': 'G', '“ì': 'g', '“ö': 'Q', '“õ': 'q', '“¢': 'N', '“£': 'n',
        '”®': 'O', '”©': 'o', '“∞': 'U', '“±': 'u', '“Æ': 'U', '“Ø': 'u', '“∫': 'H', '“ª': 'h', '–Ü': 'I', '—ñ': 'i'
    }
    return ''.join(cyrillic_to_latin.get(char, char) for char in string)


def fix_encoding(s: str) -> str:
    """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π, —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –≤ CSV."""
    if not isinstance(s, str) or not s: return s
    try: return s.encode("cp1251").decode("utf-8")
    except Exception: return s

def get_date_from_pano_id(pano_id: str) -> Optional[datetime]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ ID –ø–∞–Ω–æ—Ä–∞–º—ã, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è Unix timestamp."""
    parts = pano_id.split("_");
    if not parts: return None
    try:
        return datetime.utcfromtimestamp(int(parts[-1]))
    except (ValueError, IndexError, TypeError):
        return None

def autocrop_image(img: np.ndarray) -> np.ndarray:
    """–û–±—Ä–µ–∑–∞–µ—Ç –ø—É—Å—Ç—ã–µ (–ø–æ—á—Ç–∏ –±–µ–ª—ã–µ –∏–ª–∏ –ø–æ—á—Ç–∏ —á–µ—Ä–Ω—ã–µ) –∫—Ä–∞—è —É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mask = cv2.inRange(gray, 10, 245)
    coords = cv2.findNonZero(mask)
    if coords is None:
        return img
    x, y, w, h = cv2.boundingRect(coords)
    if w == 0 or h == 0:
        print("   -> –ê–≤—Ç–æ–æ–±—Ä–µ–∑–∫–∞ –¥–∞–ª–∞ –Ω—É–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
        return img
    return img[y:y+h, x:x+w]

# ==============================================================================
# –ì–õ–ê–í–ù–´–ô –°–ö–†–ò–ü–¢
# ==============================================================================

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∑–∞–ø—É—Å–∫–∞—é—â–∞—è –ø—Ä–æ—Ü–µ—Å—Å —Å–±–æ—Ä–∞ –ø–∞–Ω–æ—Ä–∞–º.
    """
    # --- –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ---
    parser = argparse.ArgumentParser(description="–°–±–æ—Ä—â–∏–∫ –ø–∞–Ω–æ—Ä–∞–º –Ø–Ω–¥–µ–∫—Å –ø–æ –≥–æ–¥–∞–º.")
    parser.add_argument("year", type=int, nargs='?', default=None, help="–ì–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2023). –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –±—É–¥–µ—Ç –∑–∞–ø—Ä–æ—à–µ–Ω.")
    args = parser.parse_args()
    
    if args.year:
        YEAR = str(args.year)
    else:
        YEAR = input("‚û°Ô∏è –í–≤–µ–¥–∏—Ç–µ –≥–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2023): ")
    if not YEAR.isdigit() or not (2010 < int(YEAR) < 2030):
        print(f"‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≥–æ–¥: {YEAR}. –í—ã—Ö–æ–¥."); exit()
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è {YEAR} –≥–æ–¥–∞.")

    # --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π ---
    output_dir = os.path.join(OUTPUT_DIR_BASE, YEAR)
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(TEMP_DIR, exist_ok=True)
    log_file = os.path.join(output_dir, f"metadata_{YEAR}.csv")
    bad_addresses_file = os.path.join(output_dir, f"no_panorama_addresses_{YEAR}.csv")
    state_path = os.path.join(output_dir, "state.pkl")
    cache_path = os.path.join(TEMP_DIR, "panorama_cache.pkl")
    
    # --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–æ–≤ ---
    if not os.path.exists(log_file):
        with open(log_file, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["ID", "ObjectID", "PanoID", "RoadName", "Latitude", "Longitude", "YearFound", "FilePath", "PanoramaDate"])

    # --- –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è ---
    try:
        with open(cache_path, "rb") as f: panorama_cache = pickle.load(f)
    except (FileNotFoundError, EOFError): panorama_cache = {}
    try:
        with open(state_path, "rb") as f: state = pickle.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è {YEAR} –≥–æ–¥–∞.")
    except (FileNotFoundError, EOFError):
        state = { 'processed_coords': set(), 'image_hashes': set(), 'stats': {'total_duration_seconds': 0.0} }
        print(f"‚ÑπÔ∏è –§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è {YEAR} –≥–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π.")

    processed_coords = state['processed_coords']
    image_hashes = state['image_hashes']
    stats = state['stats']
    print(f"-> –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç: {len(processed_coords)}")
    print(f"-> –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_hashes)}")

    logged_pano_ids = set()
    global_id = 0
    try:
        with open(log_file, 'r', newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row.get('PanoID'): logged_pano_ids.add(row['PanoID'])
                if row.get('ID') and row['ID'].isdigit():
                    current_id = int(row['ID'])
                    if current_id > global_id: global_id = current_id
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(logged_pano_ids)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–∞–Ω–æ—Ä–∞–º –≤ –ª–æ–≥–µ. –ù–∞—á–∞–ª—å–Ω—ã–π ID: {global_id}")
    except FileNotFoundError:
        print("‚ÑπÔ∏è –õ–æ–≥-—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω—É–ª—è.")

    # --- –ß—Ç–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---
    all_roads_data = []
    with open(INPUT_CSV, mode="r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            raw_name, object_id = (row.get("name") or row.get("name_ru") or "").strip(), row.get("objectid")
            if not raw_name or not object_id: continue
            road_name, geom = fix_encoding(raw_name), (row.get("geometry_wkt") or "").strip()
            coords_pairs = re.findall(r"([-\d\.]+)\s+([-\d\.]+)", geom)
            if not coords_pairs: continue
            path = [(float(lat), float(lon)) for lon, lat in coords_pairs]
            all_roads_data.append({ "name": road_name, "object_id": object_id, "path": path })
    if not all_roads_data:
        print("‚ö†Ô∏è –ü–æ—Å–ª–µ —á—Ç–µ–Ω–∏—è almaty_roads.csv –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –≤–∞–ª–∏–¥–Ω–æ–≥–æ –∞–¥—Ä–µ—Å–∞."); exit(1)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(all_roads_data)} –¥–æ—Ä–æ–∂–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    
    # --- –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ---
    print(">>> –°–¢–ê–†–¢ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–ª–∏—Ü")
    start_time = time.time()
    streets_processed_this_session, coords_processed_this_session = 0, 0
    total_coords_in_file = sum(len(road['path']) for road in all_roads_data)
    
    try:
        for road in all_roads_data:
            road_name, object_id, segment_path = road['name'], road['object_id'], road['path']
            print(f"\n=================================================")
            print(f"üõ£Ô∏è  –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç: ¬´{road_name}¬ª (ObjectID: {object_id})")
            
            sanitized_name = transliterate(road_name).replace(" ", "_").replace("/", "-")
            
            for lat, lon in segment_path:
                if (lat, lon) in processed_coords:
                    continue
                coords_processed_this_session += 1
                print(f"\nüìç –¢–æ—á–∫–∞: ({lat:.6f}, {lon:.6f}) [{len(processed_coords)}/{total_coords_in_file}]")
                
                pano_to_process = None
                try:
                    time.sleep(TIME_DELAY)
                    latest_pano = yandex.find_panorama(lat, lon)
                    if not latest_pano: raise StopIteration("–ü–∞–Ω–æ—Ä–∞–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–π —Ç–æ—á–∫–∏.")
                    all_panos_at_location = [latest_pano] + getattr(latest_pano, 'historical', [])
                    
                    found_pano_for_year = None
                    for pano_candidate in all_panos_at_location:
                        pano_date = getattr(pano_candidate, 'date', None) or get_date_from_pano_id(pano_candidate.id)
                        if pano_date and pano_date.year == int(YEAR):
                            if pano_candidate.id in logged_pano_ids:
                                print(f"   ‚ÑπÔ∏è –ù–∞–π–¥–µ–Ω–∞ –ø–∞–Ω–æ—Ä–∞–º–∞ {YEAR} –≥–æ–¥–∞ ({pano_candidate.id}), –Ω–æ –æ–Ω–∞ —É–∂–µ –≤ –ª–æ–≥–µ.")
                            else:
                                print(f"   üéØ –ù–∞–π–¥–µ–Ω–∞ –ø–∞–Ω–æ—Ä–∞–º–∞ –∑–∞ {YEAR} –≥–æ–¥! ID: {pano_candidate.id}")
                                found_pano_for_year = pano_candidate
                            break 
                    
                    if found_pano_for_year:
                        if getattr(found_pano_for_year, 'image_sizes', None) is None:
                            print(f"   -> –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π –ø–∞–Ω–æ—Ä–∞–º—ã...")
                            time.sleep(TIME_DELAY) 
                            pano_to_process = yandex.find_panorama_by_id(found_pano_for_year.id)
                        else:
                            pano_to_process = found_pano_for_year
                    else:
                        print(f"   ‚ÑπÔ∏è –ü–∞–Ω–æ—Ä–∞–º—ã –∑–∞ {YEAR} –≥–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–π —Ç–æ—á–∫–∏.")

                except StopIteration as e: print(f"   {e}")
                except Exception as e:
                    if "Expecting value" in str(e): print(f"   ‚ÑπÔ∏è API –Ø–Ω–¥–µ–∫—Å–∞ –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ—á–∫—É.")
                    else: print(f"   ‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                
                if pano_to_process and pano_to_process.image_sizes:
                    pano = pano_to_process
                    pano_date = getattr(pano, 'date', None) or get_date_from_pano_id(pano.id)
                    raw_path = os.path.join(TEMP_DIR, f"{pano.id}.jpg")
                    if not os.path.exists(raw_path):
                        print(f"   -> –°–∫–∞—á–∏–≤–∞–µ–º –ø–∞–Ω–æ—Ä–∞–º—É {pano.id}...")
                        yandex.download_panorama(pano, raw_path, zoom=0)
                    
                    img = cv2.imread(raw_path)
                    if img is not None:
                        cropped_img = autocrop_image(img)
                        pil_img = Image.fromarray(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
                        h_hash = imagehash.phash(pil_img)

                        if h_hash in image_hashes:
                            print(f"   ‚ÑπÔ∏è –î—É–±–ª–∏–∫–∞—Ç –ø–∞–Ω–æ—Ä–∞–º—ã (—Ç–∞–∫–æ–µ –∂–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ).")
                        else:
                            current_id = global_id + 1
                            filename = f"{YEAR}_{current_id:05d}_{sanitized_name}.jpg"
                            filepath = os.path.join(output_dir, filename)
                            cv2.imwrite(filepath, cropped_img)
                            
                            global_id, image_hashes.add(h_hash), logged_pano_ids.add(pano.id)
                            with open(log_file, "a", newline="", encoding="utf-8") as f_log:
                                writer = csv.writer(f_log)
                                writer.writerow([global_id, object_id, pano.id, road_name, pano.lat, pano.lon, YEAR, filepath, pano_date.strftime("%Y-%m-%d %H:%M:%S")])
                            print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ø–∞–Ω–æ—Ä–∞–º–∞ (–∞–≤—Ç–æ–æ–±—Ä–µ–∑–∫–∞): {filepath}")
                    else:
                        print(f"   √ó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞: {raw_path}")
                else:
                    with open(bad_addresses_file, "a", newline="", encoding="utf-8") as f_bad:
                        writer = csv.writer(f_bad); writer.writerow([road_name, lat, lon, object_id])
                
                processed_coords.add((lat, lon))
            
            streets_processed_this_session += 1
            print(f"   ‚úÖ –°–µ–≥–º–µ–Ω—Ç ¬´{road_name}¬ª (ObjectID: {object_id}) –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
    
    except KeyboardInterrupt:
        print("\n\n‚ùóÔ∏è –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
    finally:
        print("\n>>> –ó–ê–í–ï–†–®–ï–ù–ò–ï –†–ê–ë–û–¢–´...")
        session_duration_seconds = time.time() - start_time
        stats['total_duration_seconds'] += session_duration_seconds
        state['processed_coords'] = processed_coords
        state['image_hashes'] = image_hashes
        state['stats'] = stats
        with open(state_path, "wb") as f_state: pickle.dump(state, f_state)
        with open(cache_path, "wb") as f_cache: pickle.dump(panorama_cache, f_cache)
        print("   -> –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.")
        
        #–±–ª–æ–∫ –≤—ã–≤–æ–¥–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        m, s = divmod(session_duration_seconds, 60)
        h, m = divmod(m, 60)
        session_duration_formatted = f"{int(h):02d}:{int(m):02d}:{int(s):02d}"
        m_total, s_total = divmod(stats['total_duration_seconds'], 60)
        h_total, m_total = divmod(m_total, 60)
        total_duration_formatted = f"{int(h_total):02d}:{int(m_total):02d}:{int(s_total):02d}"
        print("-" * 50)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"üïí –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (—Å–µ—Å—Å–∏—è): {session_duration_formatted}")
        print(f"üïí –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–≤—Å–µ–≥–æ):  {total_duration_formatted}")
        print(f"üõ£Ô∏è  –°–µ–≥–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (—Å–µ—Å—Å–∏—è):  {streets_processed_this_session}")
        print(f"üìç –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç (–≤—Å–µ–≥–æ):         {len(processed_coords)} / {total_coords_in_file}")
        print(f"üñºÔ∏è  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ (–≤—Å–µ–≥–æ):     {global_id}")
        print("-" * 50)
        print(">>> –§–ò–ù–ò–®")

if __name__ == "__main__":
    main()